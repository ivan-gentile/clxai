# Cross-Entropy Training Configuration - CIFAR-100 + ResNet-152
# Scalability experiment: larger model + larger dataset

model:
  architecture: resnet152
  num_classes: 100

training:
  epochs: 200
  batch_size: 128
  lr: 0.1
  momentum: 0.9
  weight_decay: 0.0005
  scheduler: cosine

data:
  dataset: cifar100
  data_dir: ./data
  num_workers: 8
  augment: true

logging:
  use_wandb: true
  wandb_project: clxai
  run_name: ce_cifar100_r152
  save_freq: 50

output:
  output_dir: results/models/cifar100_r152/ce

