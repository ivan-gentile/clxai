# Supervised Contrastive Learning - ImageNet-50 + ResNet-50
# Reference: Explainable-KD-CNN (Jasper Wi) + SupCon paper (Khosla et al., NeurIPS 2020)
#
# Key changes from full ImageNet training:
# - 50-class subset (faster training)
# - RAdam optimizer (from reference code)
# - 160 epochs (supervisor recommendation)
# - pixel50 augmentation (F-Fidelity style, replacing RandomErasing)

model:
  architecture: resnet50_imagenet
  embedding_dim: 128
  pretrained: false  # Train from scratch

training:
  epochs: 160
  batch_size: 128
  
  # RAdam optimizer (from reference code)
  optimizer: radam
  lr: 0.001
  weight_decay: 0.0001
  warmup_epochs: 5
  
  # SupCon loss settings
  loss: supcon
  supcon:
    temperature: 0.07        # Critical: 0.07 >> 0.1 (learned from R152 experiments)
    base_temperature: 0.07

data:
  dataset: imagenet50        # 50-class subset
  data_dir: /leonardo_scratch/fast/CNHPC_1905882/clxai/data/imagenet-1k
  num_classes: 50
  num_workers: 8
  contrastive: true
  augmentation_type: pixel50  # F-Fidelity style (replacing RandomErasing)

evaluation:
  eval_freq: 10              # kNN every 10 epochs
  knn_k: 200
  
  # Linear probe settings (Stage 2)
  linear_probe:
    epochs: 100
    lr: 0.1
    num_classes: 50

logging:
  use_wandb: true
  wandb_project: clxai
  run_name: supcon_imagenet50_r50
  save_freq: 10

output:
  output_dir: results/models/imagenet50_r50/supcon
