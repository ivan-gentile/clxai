# Phase 4: Data Augmentation Impact Study
# Objective: Determine if augmentation is redundant for CL models

experiment:
  name: "phase4_augmentation"
  description: "Test augmentation impact on best-performing CL configuration"
  phase: 4

# Base configuration (best from Phase 3, to be updated)
# Placeholder - update after Phase 3 results
base_config:
  loss: supcon
  norm_type: bn
  weight_decay: 0.0001

# Augmentation strategies to test
augmentation_strategies:
  - name: "none"
    description: "Only normalization, no augmentation"
    transforms:
      - ToTensor
      - Normalize
  
  - name: "standard"
    description: "Random crop + horizontal flip"
    transforms:
      - RandomCrop(32, padding=4)
      - RandomHorizontalFlip
      - ToTensor
      - Normalize
  
  - name: "patch"
    description: "Standard + random patch occlusion"
    transforms:
      - RandomCrop(32, padding=4)
      - RandomHorizontalFlip
      - ToTensor
      - Normalize
      - PatchOcclusion(8, 8)
  
  - name: "noise"
    description: "Standard + Gaussian noise"
    transforms:
      - RandomCrop(32, padding=4)
      - RandomHorizontalFlip
      - ToTensor
      - Normalize
      - GaussianNoise(0.1)
  
  - name: "strong"
    description: "Standard + patch + noise"
    transforms:
      - RandomCrop(32, padding=4)
      - RandomHorizontalFlip
      - ToTensor
      - Normalize
      - PatchOcclusion(6, 6, num_patches=2)
      - GaussianNoise(0.05)

# Seeds to run
seeds: [0, 1, 2]

# Model configuration
model:
  architecture: resnet18
  num_classes: 10
  embedding_dim: 128

# Training configuration
training:
  epochs: 3000
  batch_size: 256
  lr: 0.5
  momentum: 0.9
  warmup_epochs: 10
  temperature: 0.07

# Checkpointing
checkpointing:
  epochs: [100, 200, 500, 1000, 2000, 3000]

# Evaluation settings
evaluation:
  eval_frequency: 100
  knn_k: 10
  
  adversarial:
    enabled: true
    attacks: [pgd]
    n_samples: 500
  
  faithfulness:
    enabled: true
    saliency_methods: [integrated_grad]
    n_samples: 300

# Dataset configuration
data:
  dataset: cifar10
  data_dir: /leonardo_scratch/fast/CNHPC_1905882/clxai/data
  batch_size: 256
  num_workers: 4

# Output configuration
output:
  base_dir: spline_theory/results/phase4_augmentation
  # Each config saved to: base_dir/{augmentation}_seed{seed}/

# Logging
logging:
  use_wandb: true
  wandb_project: spline_theory
  run_name_template: "phase4_{augmentation}_seed{seed}"

# Key hypothesis to test
hypothesis:
  name: "CL makes augmentation redundant"
  prediction: "CL models achieve similar faithfulness regardless of augmentation level"
  metrics_to_compare:
    - auc_deletion
    - auc_insertion
    - pgd_accuracy
    - embedding_smoothness

# Resource estimates
resources:
  gpu_hours_per_augmentation: 6
  total_augmentations: 5
  total_seeds: 3
  estimated_total_hours: 90
