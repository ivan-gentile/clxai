# Phase 3: Contrastive Learning Ablation Study
# Objective: Understand which factors make CL effective for faithfulness

experiment:
  name: "phase3_cl_ablation"
  description: "Full factorial ablation on CL training configurations"
  phase: 3

# Ablation factors
ablation:
  # Loss functions
  loss:
    - supcon
    - triplet
  
  # Weight decay levels
  weight_decay:
    - 0.0      # R0: No regularization
    - 0.00001  # R2: Light (1e-5)
    - 0.0001   # R3: Standard (1e-4)
  
  # Normalization types
  norm_type:
    - bn  # BatchNorm
    - gn  # GroupNorm (32 groups)
    - id  # Identity (no norm)

# Total configurations: 2 x 3 x 3 = 18
# Total runs with seeds: 18 x 3 = 54

# Seeds to run
seeds: [0, 1, 2]

# Model configuration
model:
  architecture: resnet18
  num_classes: 10
  embedding_dim: 128

# Training configuration
training:
  epochs: 3000
  batch_size: 256
  lr: 0.5
  momentum: 0.9
  warmup_epochs: 10
  scheduler: cosine_with_warmup
  
  # Loss-specific settings
  supcon:
    temperature: 0.07
  
  triplet:
    margin: 0.3
    mining: hard

# Checkpointing
checkpointing:
  epochs: [100, 200, 300, 500, 750, 1000, 1500, 2000, 3000]
  save_optimizer: true

# Evaluation settings
evaluation:
  eval_frequency: 50
  knn_k: 10
  
  # Full evaluation at checkpoints
  adversarial:
    enabled: true
    attacks: [fgsm, pgd]
    n_samples: 500
  
  faithfulness:
    enabled: true
    n_samples: 200

# Dataset configuration
data:
  dataset: cifar10
  data_dir: /leonardo_scratch/fast/CNHPC_1905882/clxai/data
  batch_size: 256
  num_workers: 4
  contrastive: true  # Enable two-view augmentation for SupCon
  augment: true

# Output configuration
output:
  base_dir: spline_theory/results/phase3_ablation
  # Each config saved to: base_dir/{loss}_{norm}_{wd}_seed{seed}/

# Logging
logging:
  use_wandb: true
  wandb_project: spline_theory
  run_name_template: "phase3_{loss}_{norm}_wd{wd}_seed{seed}"

# Resource estimates
resources:
  gpu_hours_per_config: 6  # ~3000 epochs
  total_configs: 18
  total_seeds: 3
  estimated_total_hours: 324
